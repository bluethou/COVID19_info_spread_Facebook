{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tutorial (v1.7.0): Contexutalized Topic Modeling with your Documents (with preprocessing). 의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4762044d491b4a3a83dc95200ef68eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca8b71277bfa42179137d78528aa0637",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e34adcc209140b9930f55afb4158c7c",
              "IPY_MODEL_41c36f22470e4cd7b72f51bd1265c75d"
            ]
          }
        },
        "ca8b71277bfa42179137d78528aa0637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e34adcc209140b9930f55afb4158c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d6a6db3b46324c2da93c0909a83690f8",
            "_dom_classes": [],
            "description": "Batches: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 15,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 15,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db515e4939af4f1db42243d91027a8c3"
          }
        },
        "41c36f22470e4cd7b72f51bd1265c75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4bd9df9808a64245bf620354c8371e2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 15/15 [00:08&lt;00:00,  1.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f0c39e2a68749f19768b3b12534461b"
          }
        },
        "d6a6db3b46324c2da93c0909a83690f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db515e4939af4f1db42243d91027a8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bd9df9808a64245bf620354c8371e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f0c39e2a68749f19768b3b12534461b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmZ1uZecv7qW"
      },
      "source": [
        "# Tutorial: Contextualized Topic Models with Wikipedia Documents\n",
        "\n",
        "(last updated 5-11-2020)\n",
        "\n",
        "In this tutorial, we are going to use contextualized topic modeling to get topics out of a collections of articles you will upload here.\n",
        "\n",
        "## Topic Models \n",
        "\n",
        "Topic models allow you to discover latent topics in your documents in a completely unsupervised way. Just use your documents and get topics out.\n",
        "\n",
        "## Contextualized Topic Models\n",
        "\n",
        "![](https://raw.githubusercontent.com/MilaNLProc/contextualized-topic-models/master/img/logo.png)\n",
        "\n",
        "What are Contextualized Topic Models? **CTMs** are a family of topic models that combine the expressive power of BERT embeddings with the unsupervised capabilities of topic models to get topics out of documents.\n",
        "\n",
        "## Python Package\n",
        "\n",
        "You can find our package [here](https://github.com/MilaNLProc/contextualized-topic-models).\n",
        "\n",
        "![https://travis-ci.com/MilaNLProc/contextualized-topic-models](https://travis-ci.com/MilaNLProc/contextualized-topic-models.svg) ![https://pypi.python.org/pypi/contextualized_topic_models](https://img.shields.io/pypi/v/contextualized_topic_models.svg) ![https://pepy.tech/badge/contextualized-topic-models](https://pepy.tech/badge/contextualized-topic-models)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln23-soXeQk3"
      },
      "source": [
        "# Enabling the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Edit→Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "[Reference](https://colab.research.google.com/notebooks/gpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgxRbgSZ9MsB"
      },
      "source": [
        "# Data\n",
        "\n",
        "We are going to need some data. You should upload a file with one document per line. We assume you haven't run any preprocessing script.\n",
        "\n",
        "However, if you want to first test the model without uploading your data, you can simply use the test file I'm putting here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZEPr_QFJdBz"
      },
      "source": [
        "# !wget https://raw.githubusercontent.com/vinid/data/master/dbpedia_sample_abstract_20k_unprep.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKZ9Yk0qJvxd"
      },
      "source": [
        "# !head -n 1 dbpedia_sample_abstract_20k_unprep.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "B2rlDIA6T6Ek",
        "outputId": "1b4a8b86-d862-42b6-e8c4-7bbfa8e6ad65"
      },
      "source": [
        "from google.colab import files \n",
        "uploaded = files.upload() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3d19cb59-81aa-4c5f-9192-b893ecabbd2b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3d19cb59-81aa-4c5f-9192-b893ecabbd2b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving COVID_1year_group_3000.csv to COVID_1year_group_3000.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXZ8fOdYwdWO"
      },
      "source": [
        "text_file = \"COVID_1year_group_3000.csv\" # EDIT THIS WITH THE FILE YOU UPLOAD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsNRo8I8Yem2"
      },
      "source": [
        "# Installing Contextualized Topic Models\n",
        "\n",
        "Now, we install the contextualized topic model library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUw5EQi8v9r1",
        "outputId": "c400f4e5-180e-4a7b-c0ef-bb14c99dcdb3"
      },
      "source": [
        "!pip install contextualized-topic-models==1.7.0\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contextualized-topic-models==1.7.0 in /usr/local/lib/python3.6/dist-packages (1.7.0)\n",
            "Requirement already satisfied: sentence-transformers==0.3.6 in /usr/local/lib/python3.6/dist-packages (from contextualized-topic-models==1.7.0) (0.3.6)\n",
            "Requirement already satisfied: gensim==3.8.3 in /usr/local/lib/python3.6/dist-packages (from contextualized-topic-models==1.7.0) (3.8.3)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from contextualized-topic-models==1.7.0) (1.6.0)\n",
            "Requirement already satisfied: torchvision==0.7.0 in /usr/local/lib/python3.6/dist-packages (from contextualized-topic-models==1.7.0) (0.7.0)\n",
            "Requirement already satisfied: numpy==1.19.1 in /usr/local/lib/python3.6/dist-packages (from contextualized-topic-models==1.7.0) (1.19.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (3.2.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (0.22.2.post1)\n",
            "Requirement already satisfied: transformers<3.2.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (3.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (4.41.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.3->contextualized-topic-models==1.7.0) (4.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.3->contextualized-topic-models==1.7.0) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->contextualized-topic-models==1.7.0) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0->contextualized-topic-models==1.7.0) (7.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (1.0.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (0.1.95)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (0.8.1rc2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.2.0,>=3.1.0->sentence-transformers==0.3.6->contextualized-topic-models==1.7.0) (2.4.7)\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (708.0MB)\n",
            "\u001b[K     |████████████████████████████████| 708.0MB 25kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.7.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (1.19.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0\n",
            "    Uninstalling torch-1.6.0:\n",
            "      Successfully uninstalled torch-1.6.0\n",
            "  Found existing installation: torchvision 0.7.0\n",
            "    Uninstalling torchvision-0.7.0:\n",
            "      Successfully uninstalled torchvision-0.7.0\n",
            "Successfully installed torch-1.6.0+cu101 torchvision-0.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0c_ftxjxY_H"
      },
      "source": [
        "## Importing what we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZmTpQUov8y8"
      },
      "source": [
        "from contextualized_topic_models.models.ctm import CombinedTM\n",
        "from contextualized_topic_models.utils.data_preparation import bert_embeddings_from_list, QuickText\n",
        "from contextualized_topic_models.datasets.dataset import CTMDataset\n",
        "from contextualized_topic_models.evaluation.measures import CoherenceNPMI, InvertedRBO\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import ldamodel \n",
        "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessing\n",
        "import nltk\n",
        "import os\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQkeIrdWLU2m"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-AM070Ez6lW"
      },
      "source": [
        "Let's pass our file with preprocess data to our text handler object. This object takes care of creating the bag of words for you.\n",
        "\n",
        "Why do we use the **preprocessed text** here? we need text without punctuation to build the bag of word. Also, we might want only to have the most frequent words inside the BoW. Too many words might not help."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXYy3qBEP7Lx"
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovxb3dhHVCyX",
        "outputId": "db87cb0e-1d05-4e37-f7e2-03d486bc47a7"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "documents = pd.read_csv(text_file)['Message'][:3000]\n",
        "# documents = [line.strip() for line in open(text_file, encoding=\"utf-8\").readlines()][:3000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ez-6p7KR3RH",
        "outputId": "e0fe49a4-2eb2-4a89-9cff-a2449761ba6e"
      },
      "source": [
        "documents"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Remember Danielle DiCenso, the nurse age 33 wh...\n",
              "1       Our Father Who art in heaven, Hallowed be his ...\n",
              "2                              Death liability waiver. :(\n",
              "3       The reason Dr. Fauci, our leading infectious d...\n",
              "4       This is my brother Rob He let his wife cut his...\n",
              "                              ...                        \n",
              "2995    How is everyone?‼‼ ️ This is not fraud. 😍 I'am...\n",
              "2996    I am pissed, I am so very angry. Why? Let me t...\n",
              "2997                                                   Up\n",
              "2998                                   More good news 🙏🙏🙏\n",
              "2999    Good Evening All, I don't have the Time to Rea...\n",
              "Name: Message, Length: 3000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLHT0jKwAJQK"
      },
      "source": [
        "# # news_df['clean_doc'].apply(lambda x: str(x).lower())\n",
        "# # doc.lower() for doc in preprocessed_docs_tmp\n",
        "# documents.apply(lambda x: str(x).lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZesienJVHMt"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import string\n",
        "from nltk.corpus import stopwords as stop_words\n",
        "import warnings\n",
        "documents = documents\n",
        "stopwords = set(stop_words.words(\"english\"))\n",
        "stopwords.update([\"html\",\"com\",\"https\",\"www\",\"fwww\", \"dhttps\",\"flogin\",\"utm\", \"fnext\",\"cnn\",\"fox\",\"foxnews\",\"covid\",\"coronavirus\"])\n",
        "vocabulary_size = 2000\n",
        "\n",
        "preprocessed_docs_tmp = documents\n",
        "preprocessed_docs_tmp = preprocessed_docs_tmp.apply(lambda x: str(x).lower())\n",
        "preprocessed_docs_tmp = [doc.translate(\n",
        "    str.maketrans(string.punctuation, ' ' * len(string.punctuation))) for doc in preprocessed_docs_tmp]\n",
        "preprocessed_docs_tmp = [' '.join([w for w in doc.split() if len(w) > 3 and w not in stopwords])\n",
        "                      for doc in preprocessed_docs_tmp]\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=vocabulary_size, token_pattern=r'\\b[a-zA-Z]{2,}\\b')\n",
        "vectorizer.fit_transform(preprocessed_docs_tmp)\n",
        "vocabulary = set(vectorizer.get_feature_names())\n",
        "preprocessed_docs_tmp = [' '.join([w for w in doc.split() if w in vocabulary])\n",
        "                          for doc in preprocessed_docs_tmp]\n",
        "\n",
        "preprocessed_docs, unpreprocessed_docs = [], []\n",
        "cnt=0\n",
        "index=[]\n",
        "for i, doc in enumerate(preprocessed_docs_tmp):\n",
        "  if len(doc) > 0:\n",
        "    index.append(cnt)\n",
        "    preprocessed_docs.append(doc)\n",
        "    unpreprocessed_docs.append(documents[i])\n",
        "  cnt=cnt+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW7L_64eVTvV"
      },
      "source": [
        "preprocessed_documents, unpreprocessed_corpus, vocab = preprocessed_docs, unpreprocessed_docs, list(vocabulary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKrSIkxaNBt"
      },
      "source": [
        "# nltk.download('stopwords')\n",
        "\n",
        "# documents = [line.strip() for line in open(text_file, encoding=\"utf-8\").readlines()]\n",
        "# sp = WhiteSpacePreprocessing(documents, \"english\")\n",
        "# preprocessed_documents, unpreprocessed_corpus, vocab = sp.preprocess()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu0HY7KWGrk1"
      },
      "source": [
        "You might want to pickle the **training_dataset** object to avoid recomputing the BoW multiple times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhLt6VA3wvCB"
      },
      "source": [
        "qt = QuickText(\"bert-base-nli-mean-tokens\",\n",
        "            text_for_bert=unpreprocessed_corpus,\n",
        "            text_for_bow=preprocessed_documents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "4762044d491b4a3a83dc95200ef68eab",
            "ca8b71277bfa42179137d78528aa0637",
            "9e34adcc209140b9930f55afb4158c7c",
            "41c36f22470e4cd7b72f51bd1265c75d",
            "d6a6db3b46324c2da93c0909a83690f8",
            "db515e4939af4f1db42243d91027a8c3",
            "4bd9df9808a64245bf620354c8371e2a",
            "5f0c39e2a68749f19768b3b12534461b"
          ]
        },
        "id": "9I3ThmBf0BcK",
        "outputId": "83384451-aac4-471b-88bb-fe61b9feb697"
      },
      "source": [
        "training_dataset = qt.load_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:13<00:00, 31.1MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4762044d491b4a3a83dc95200ef68eab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batches', max=15.0, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5agbVqhxdnY"
      },
      "source": [
        "## Training our Contextualized Topic Model\n",
        "\n",
        "Finally, we can fit our new topic model. We will ask the model to find 50 topics in our collection (n_component parameter of the CTM object)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dALamw7HxLj-"
      },
      "source": [
        "ctm = CombinedTM(input_size=len(qt.vocab), bert_input_size=768, n_components=10, num_epochs=1000)\n",
        "\n",
        "ctm.fit(training_dataset) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SEBG6wj9Zdu"
      },
      "source": [
        "# Topics\n",
        "\n",
        "After training, now it is the time to look at our topics: we can use the \n",
        "\n",
        "```\n",
        "get_topic_lists\n",
        "```\n",
        "\n",
        "function to get the topics. It also accepts a parameter that allows you to select how many words you want to see for each topic.\n",
        "\n",
        "If you look at the topics, you will see that they all make sense and are representative of a collection of documents that comes from Wikipedia (general knowledge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxcKgjbx3V2o",
        "outputId": "c6ee934e-3c3d-4324-85e2-0a2594f929ed"
      },
      "source": [
        "print(ctm.get_topic_lists(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['successful', 'exercise', 'thanksgiving', 'copied', 'decisions', 'wore', 'sound', 'enemy', 'onto', 'decades'], ['trump', 'government', 'country', 'president', 'vaccine', 'gates', 'media', 'african', 'lockdown', 'billion'], ['sing', 'join', 'battle', 'sharing', 'welsh', 'lost', 'joining', 'anthem', 'tomorrow', 'wales'], ['jesus', 'pray', 'amen', 'lord', 'holy', 'mary', 'heart', 'love', 'mother', 'mercy'], ['million', 'share', 'name', 'fraud', 'nombre', 'para', 'organization', 'register', 'post', 'group'], ['health', 'class', 'public', 'department', 'employees', 'quarantine', 'center', 'said', 'medical', 'office'], ['successful', 'thanksgiving', 'exercise', 'decisions', 'copied', 'wore', 'sound', 'rise', 'realize', 'experiencing'], ['people', 'virus', 'patients', 'health', 'also', 'disease', 'like', 'many', 'deaths', 'care'], ['time', 'home', 'work', 'every', 'would', 'please', 'kids', 'know', 'make', 'need'], ['please', 'hospital', 'mask', 'hours', 'still', 'need', 'phone', 'room', 'someone', 'take']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeNJfHvzjD2R"
      },
      "source": [
        "### Let's find our documents' topics\n",
        "\n",
        "Ok now we can take a document and see which topic has been asigned to it. Results will obviously change with respect to the documents you are using. For example, let's predict the topic of the first preprocessed document that is taling about a peninsula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl5O1HExjI0e"
      },
      "source": [
        "topics_predictions = ctm.get_thetas(training_dataset, n_samples=20) # get all the topic predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QAtVoIHAZOq",
        "outputId": "3c670971-597e-45f0-e1b2-7fea4e10f8c3"
      },
      "source": [
        "topics_predictions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2860, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "fFWsIxDYj0pC",
        "outputId": "15ebd282-a1cb-473c-dd32-1a4ce08fa64f"
      },
      "source": [
        "preprocessed_documents[-1] # see the text of our preprocessed document"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'good evening time read people taking virus another positive case area lost person needed fight behalf members wish family soul rest peace clinical trials unit unit director prevention research unit south african medical research council south africa trials working wife passed away london'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJf1bP5PjqOQ"
      },
      "source": [
        "import numpy as np\n",
        "topic_number = np.argmax(topics_predictions[0]) # get the topic id of the first document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMA9vUsgjwOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388594a8-3416-4e4a-9079-dccac9e73ed3"
      },
      "source": [
        "ctm.get_topic_lists(5)[topic_number] #and the topic should and could be about nature/locations related things"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sing', 'join', 'battle', 'sharing', 'welsh']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpJ9LIziH3jQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4e68309d-d0e5-4629-90ea-4be2b3ae612c"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "result_df = pd.DataFrame(topics_predictions).assign(index=index)\n",
        "result_df.to_csv('topics_predictions.csv') \n",
        "files.download('topics_predictions.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3678a1d5-bd3b-4f41-969e-53e34dd03c81\", \"topics_predictions.csv\", 600713)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMsXOMURTlH6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}